<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.97.3" />
<link rel="canonical" type="text/html" href="/v0.1/guides/">
<link rel="alternate" type="application/rss&#43;xml" href="/v0.1/guides/index.xml">
<meta name="robots" content="noindex, nofollow">


<link rel="shortcut icon" href="/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/favicons/android-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/favicons/android-192x192.png" sizes="192x192">

<title>Guides | Omni</title>
<meta name="description" content="">
<meta property="og:title" content="Guides" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="/v0.1/guides/" />

<meta itemprop="name" content="Guides">
<meta itemprop="description" content=""><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Guides"/>
<meta name="twitter:description" content=""/>




<link rel="preload" href="/scss/main.min.0ef68169fe3e3f67b5cf6bc5f00f55fa4cd0402d35e7d812ee541930f94707e6.css" as="style">
<link href="/scss/main.min.0ef68169fe3e3f67b5cf6bc5f00f55fa4cd0402d35e7d812ee541930f94707e6.css" rel="stylesheet" integrity="">

<script
  src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
  crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3"/>
<link rel="stylesheet" type="text/css" href="/asciinema/asciinema-player.css" />






  
  
  
    
    
  


<script async src="https://www.googletagmanager.com/gtag/js?id=G-SFLNPVQLRL"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-SFLNPVQLRL', { 'anonymize_ip': false });
}
</script>

  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/">
		<span class="navbar-logo"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 203.74 226.05"><defs><style>.cls-1{fill:url(#linear-gradient)}.cls-2{fill:url(#linear-gradient-2)}.cls-3{fill:url(#linear-gradient-3)}.cls-4{fill:url(#linear-gradient-4)}.cls-5{fill:url(#linear-gradient-5)}</style><linearGradient id="linear-gradient" x1="101.85" y1="-12.91" x2="101.85" y2="224.04" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#ffd200"/><stop offset=".08" stop-color="#ffb500"/><stop offset=".2" stop-color="#ff8c00"/><stop offset=".3" stop-color="#ff7300"/><stop offset=".36" stop-color="#ff6a00"/><stop offset=".48" stop-color="#fc4f0e"/><stop offset=".65" stop-color="#f92f1e"/><stop offset=".79" stop-color="#f81b27"/><stop offset=".89" stop-color="#f7142b"/><stop offset="1" stop-color="#df162e"/></linearGradient><linearGradient id="linear-gradient-2" x1="24.84" y1="-12.91" x2="24.84" y2="224.04" xlink:href="#linear-gradient"/><linearGradient id="linear-gradient-3" x1="178.9" y1="-12.91" x2="178.9" y2="224.04" xlink:href="#linear-gradient"/><linearGradient id="linear-gradient-4" x1="145.06" y1="-12.91" x2="145.06" y2="224.04" xlink:href="#linear-gradient"/><linearGradient id="linear-gradient-5" x1="58.64" y1="-12.91" x2="58.64" y2="224.04" xlink:href="#linear-gradient"/></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><path class="cls-1" d="M101.89 226.05c2.85.0 5.67-.15 8.46-.35V.35c-2.8-.21-5.62-.35-8.48-.35s-5.7.14-8.52.35V225.69c2.81.21 5.64.35 8.5.36z"/><path class="cls-2" d="M11.56 50.9 9.12 48.47A112.82 112.82.0 00.2 63.61c29.42 29.89 32.52 44.31 32.48 49.14C32.57 125 17.58 144.21.0 162a113.69 113.69.0 008.84 15.15c1-1 1.95-1.92 2.92-2.9 25.37-25.54 37.77-45.61 37.92-61.38S37.36 77 11.56 50.9z"/><path class="cls-3" d="M192 174.29l2.92 2.9A113.69 113.69.0 00203.74 162c-17.57-17.83-32.56-37.09-32.68-49.29-.11-11.9 14.79-31.15 32.46-49.18a112.88 112.88.0 00-8.9-15.1l-2.44 2.43c-25.8 26.05-38.27 46.34-38.12 62s12.55 35.89 37.94 61.43z"/><path class="cls-4" d="M140.68 112.83c0-22 9.81-58.58 24.92-93.15A113 113 0 00150.45 11c-16.54 37.27-26.78 76.91-26.78 101.87.0 24.15 11.09 64.23 27.93 101.7a113 113 0 0014.84-8.77c-15.59-35.07-25.76-71.73-25.76-92.97z"/><path class="cls-5" d="M80 112.83C80 87.74 69.35 47.88 53 11.07a112.76 112.76.0 00-14.93 8.64C53.21 54.26 63 90.85 63 112.83c0 21.23-10.17 57.88-25.76 92.91a113.66 113.66.0 0014.84 8.77C68.94 177.05 80 137 80 112.83z"/></g></g></svg></span><span class="text-uppercase font-weight-bold">Omni</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="navbar-nav">
			
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="https://talos.dev" target="_blank" ><span>Talos Linux</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="https://github.com/siderolabs" target="_blank" ><span>GitHub</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="https://www.siderolabs.com" target="_blank" ><span>Sidero Labs</span></a>
			</li>
			
			
			<li class="nav-item dropdown mr-4 d-none d-lg-block">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	Releases
</a>
<div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="/v0.6">v0.6 (pre-release)</a>
	
	<a class="dropdown-item" href="/v0.5">v0.5 (latest)</a>
	
	<a class="dropdown-item" href="/v0.4">v0.4</a>
	
	<a class="dropdown-item" href="/v0.3">v0.3</a>
	
	<a class="dropdown-item" href="/v0.2">v0.2</a>
	
	<a class="dropdown-item" href="/v0.1">v0.1</a>
	
</div>

			</li>
			
			
      <li id="algolia-search"></li>
		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block"></div>
</nav>

    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This is the multi-page printable view of this section.
<a href="#" onclick="print();return false;">Click here to print</a>.
</p><p>
<a href="/v0.1/guides/">Return to the regular view of this page</a>.
</p>
</div>



<h1 class="title">Guides</h1>





    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-3f8d958fc762494c26d399fcd75ba217">Bootstrapping</a></li>


    
  
    
    
	
<li>2: <a href="#pg-4d9f3827e7755ecc806058696c1d2359">Creating Your First Cluster</a></li>


    
  
    
    
	
<li>3: <a href="#pg-6a83ec7ccd4d033a9248a54355ce6a91">Patching</a></li>


    
  
    
    
	
<li>4: <a href="#pg-c0b04d8cb5ac9d8994644df9aea859db">Provisioning Flow</a></li>


    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-3f8d958fc762494c26d399fcd75ba217">1 - Bootstrapping</h1>
    <div class="lead">A guide for bootstrapping Sidero management plane</div>
	<h2 id="introduction">Introduction</h2>
<p>Imagine a scenario in which you have shown up to a datacenter with only a laptop and your task is to transition a rack of bare metal machines into an HA management plane and multiple Kubernetes clusters created by that management plane.
In this guide, we will go through how to create a bootstrap cluster using a Docker-based Talos cluster, provision the management plane, and pivot over to it.
Guides around post-pivoting setup and subsequent cluster creation should also be found in the &ldquo;Guides&rdquo; section of the sidebar.</p>
<p>Because of the design of Cluster API, there is inherently a &ldquo;chicken and egg&rdquo; problem with needing a Kubernetes cluster in order to provision the management plane.
Talos Systems and the Cluster API community have created tools to help make this transition easier.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>First, you need to install the latest <code>talosctl</code> by running the following script:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -Lo /usr/local/bin/talosctl https://github.com/talos-systems/talos/releases/latest/download/talosctl-<span style="color:#719e07">$(</span>uname -s | tr <span style="color:#2aa198">&#34;[:upper:]&#34;</span> <span style="color:#2aa198">&#34;[:lower:]&#34;</span><span style="color:#719e07">)</span>-amd64
</span></span><span style="display:flex;"><span>chmod +x /usr/local/bin/talosctl
</span></span></code></pre></div><p>You can read more about Talos and <code>talosctl</code> at <a href="https://www.talos.dev/latest">talos.dev</a>.</p>
<p>Next, there are two big prerequisites involved with bootstrapping Sidero: routing and DHCP setup.</p>
<p>From the routing side, the laptop from which you are bootstrapping <em>must</em> be accessible by the bare metal machines that we will be booting.
In the datacenter scenario described above, the easiest way to achieve this is probably to hook the laptop onto the server rack&rsquo;s subnet by plugging it into the top-of-rack switch.
This is needed for TFTP, PXE booting, and for the ability to register machines with the bootstrap plane.</p>
<p>DHCP configuration is needed to tell the metal servers what their &ldquo;next server&rdquo; is when PXE booting.
The configuration of this is different for each environment and each DHCP server, thus it&rsquo;s impossible to give an easy guide.
However, here is an example of the configuration for an Ubiquti EdgeRouter that uses vyatta-dhcpd as the DHCP service:</p>
<p>This block shows the subnet setup, as well as the extra &ldquo;subnet-parameters&rdquo; that tell the DHCP server to include the ipxe-metal.conf file.</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ show service dhcp-server shared-network-name MetalDHCP
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> authoritative <span style="color:#b58900">enable</span>
</span></span><span style="display:flex;"><span> subnet 192.168.254.0/24 <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>     default-router 192.168.254.1
</span></span><span style="display:flex;"><span>     dns-server 192.168.1.200
</span></span><span style="display:flex;"><span>     lease <span style="color:#2aa198">86400</span>
</span></span><span style="display:flex;"><span>     start 192.168.254.2 <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>         stop 192.168.254.252
</span></span><span style="display:flex;"><span>     <span style="color:#719e07">}</span>
</span></span><span style="display:flex;"><span>     subnet-parameters <span style="color:#2aa198">&#34;include &amp;quot;/etc/dhcp/ipxe-metal.conf&amp;quot;;&#34;</span>
</span></span><span style="display:flex;"><span> <span style="color:#719e07">}</span>
</span></span></code></pre></div><p>Here is the ipxe-metal.conf file.</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ cat /etc/dhcp/ipxe-metal.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>allow bootp;
</span></span><span style="display:flex;"><span>allow booting;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>next-server 192.168.1.150;
</span></span><span style="display:flex;"><span><span style="color:#719e07">if</span> exists user-class and option user-class <span style="color:#719e07">=</span> <span style="color:#2aa198">&#34;iPXE&#34;</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>  filename <span style="color:#2aa198">&#34;http://192.168.1.150:8081/boot.ipxe&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#719e07">}</span> elsif substring <span style="color:#719e07">(</span>option vendor-class-identifier, 0, 10<span style="color:#719e07">)</span> <span style="color:#719e07">=</span> <span style="color:#2aa198">&#34;HTTPClient&#34;</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>  option vendor-class-identifier <span style="color:#2aa198">&#34;HTTPClient&#34;</span>;
</span></span><span style="display:flex;"><span>  filename <span style="color:#2aa198">&#34;http://192.168.1.150:8081/tftp/ipxe.efi&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#719e07">}</span> <span style="color:#719e07">else</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>  filename <span style="color:#2aa198">&#34;ipxe.efi&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#719e07">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>host talos-mgmt-0 <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>    fixed-address 192.168.254.2;
</span></span><span style="display:flex;"><span>    hardware ethernet d0:50:99:d3:33:60;
</span></span><span style="display:flex;"><span><span style="color:#719e07">}</span>
</span></span></code></pre></div><p>Notice that it sets a static address for the management node that I&rsquo;ll be booting, in addition to providing the &ldquo;next server&rdquo; info.
This &ldquo;next server&rdquo; IP address will match references to <code>PUBLIC_IP</code> found below in this guide.</p>
<h2 id="create-a-local-cluster">Create a Local Cluster</h2>
<p>The <code>talosctl</code> CLI tool has built-in support for spinning up Talos in docker containers.
Let&rsquo;s use this to our advantage as an easy Kubernetes cluster to start from.</p>
<p>Set an environment variable called <code>PUBLIC_IP</code> which is the &ldquo;public&rdquo; IP of your machine.
Note that &ldquo;public&rdquo; is a bit of a misnomer.
We&rsquo;re really looking for the IP of your machine, not the IP of the node on the docker bridge (ex: <code>192.168.1.150</code>).</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#b58900">export</span> <span style="color:#268bd2">PUBLIC_IP</span><span style="color:#719e07">=</span><span style="color:#2aa198">&#34;192.168.1.150&#34;</span>
</span></span></code></pre></div><p>We can now create our Docker cluster.
Issue the following to create a single-node cluster:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>talosctl cluster create <span style="color:#cb4b16">\
</span></span></span><span style="display:flex;"><span><span style="color:#cb4b16"></span>  -p 69:69/udp,8081:8081/tcp,9091:9091/tcp,50100:50100/tcp <span style="color:#cb4b16">\
</span></span></span><span style="display:flex;"><span><span style="color:#cb4b16"></span>  --workers <span style="color:#2aa198">0</span> <span style="color:#cb4b16">\
</span></span></span><span style="display:flex;"><span><span style="color:#cb4b16"></span>  --endpoint <span style="color:#268bd2">$PUBLIC_IP</span>
</span></span></code></pre></div><p>Note that there are several ports mentioned in the command above.
These allow us to access the services that will get deployed on this node.</p>
<p>Once the cluster create command is complete, issue <code>talosctl kubeconfig /desired/path</code> to fetch the kubeconfig for this cluster.
You should then set your <code>KUBECONFIG</code> environment variable to the path of this file.</p>
<h2 id="untaint-control-plane">Untaint Control Plane</h2>
<p>Because this is a single node cluster, we need to remove the &ldquo;NoSchedule&rdquo; taint on the node to make sure non-controlplane components can be scheduled.</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl taint node talos-default-master-1 node-role.kubernetes.io/master:NoSchedule-
</span></span></code></pre></div><h2 id="install-sidero">Install Sidero</h2>
<p>As of Cluster API version 0.3.9, Sidero is included as a default infrastructure provider in clusterctl.</p>
<p>To install Sidero and the other Talos providers, simply issue:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>clusterctl init -b talos -c talos -i sidero
</span></span></code></pre></div><h2 id="patch-components">Patch Components</h2>
<p>We will now want to ensure that the Sidero services that got created are publicly accessible across our subnet.
This will allow the metal machines to speak to these services later.</p>
<h3 id="patch-the-metadata-server">Patch the Metadata Server</h3>
<p>Update the metadata server component with the following patches:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#586e75">## Update args to use 9091 for port</span>
</span></span><span style="display:flex;"><span>kubectl patch deploy -n sidero-system sidero-metadata-server --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/args&#34;, &#34;value&#34;: [&#34;--port=9091&#34;]}]&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#586e75">## Tweak container port to match</span>
</span></span><span style="display:flex;"><span>kubectl patch deploy -n sidero-system sidero-metadata-server --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/ports&#34;, &#34;value&#34;: [{&#34;containerPort&#34;: 9091,&#34;name&#34;: &#34;http&#34;}]}]&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#586e75">## Use host networking</span>
</span></span><span style="display:flex;"><span>kubectl patch deploy -n sidero-system sidero-metadata-server --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/spec/template/spec/hostNetwork&#34;, &#34;value&#34;: true}]&#39;</span>
</span></span></code></pre></div><h3 id="patch-the-metal-controller-manager">Patch the Metal Controller Manager</h3>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#586e75">## Update args to specify the api endpoint to use for registration</span>
</span></span><span style="display:flex;"><span>kubectl patch deploy -n sidero-system sidero-controller-manager --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/1/args&#34;, &#34;value&#34;: [&#34;--api-endpoint=&#39;</span><span style="color:#268bd2">$PUBLIC_IP</span><span style="color:#2aa198">&#39;&#34;,&#34;--metrics-addr=127.0.0.1:8080&#34;,&#34;--enable-leader-election&#34;]}]&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#586e75">## Use host networking</span>
</span></span><span style="display:flex;"><span>kubectl patch deploy -n sidero-system sidero-controller-manager --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/spec/template/spec/hostNetwork&#34;, &#34;value&#34;: true}]&#39;</span>
</span></span></code></pre></div><h2 id="register-the-servers">Register the Servers</h2>
<p>At this point, any servers on the same network as Sidero should PXE boot using the Sidero PXE service.
To register a server with Sidero, simply turn it on and Sidero will do the rest.
Once the registration is complete, you should see the servers registered with <code>kubectl get servers</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get servers -o wide
</span></span><span style="display:flex;"><span>NAME                                   HOSTNAME        ACCEPTED   ALLOCATED   CLEAN
</span></span><span style="display:flex;"><span>00000000-0000-0000-0000-d05099d33360   192.168.254.2   <span style="color:#b58900">false</span>      <span style="color:#b58900">false</span>       <span style="color:#b58900">false</span>
</span></span></code></pre></div><h2 id="accept-the-servers">Accept the Servers</h2>
<p>Note in the output above that the newly registered servers are not <code>accepted</code>.
In order for a server to be eligible for consideration, it <em>must</em> be marked as <code>accepted</code>.
Before a <code>Server</code> is accepted, no write action will be performed against it.
Servers can be accepted by issuing a patch command like:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl patch server 00000000-0000-0000-0000-d05099d33360 --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/accepted&#34;, &#34;value&#34;: true}]&#39;</span>
</span></span></code></pre></div><p>For more information on server acceptance, see the <a href="/docs/v0.1/configuration/servers">server docs</a>.</p>
<h2 id="create-the-default-environment">Create the Default Environment</h2>
<p>We must now create an <code>Environment</code> in our bootstrap cluster.
An environment is a CRD that tells the PXE component of Sidero what information to return to nodes that request a PXE boot after completing the registration process above.
Things that can be controlled here are kernel flags and the kernel and init images to use.</p>
<p>To create a default environment that will use the latest published Talos release, issue the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#2aa198">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">apiVersion: metal.sidero.dev/v1alpha1
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">kind: Environment
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">  name: default
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">  kernel:
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">    url: &#34;https://github.com/talos-systems/talos/releases/latest/download/vmlinuz-amd64&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">    sha512: &#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">    args:
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - initrd=initramfs.xz
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - page_poison=1
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - slab_nomerge
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - slub_debug=P
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - pti=on
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - random.trust_cpu=on
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - ima_template=ima-ng
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - ima_appraise=fix
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - ima_hash=sha512
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - console=tty0
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - console=ttyS1,115200n8
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - earlyprintk=ttyS1,115200n8
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - panic=0
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - printk.devkmsg=on
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - talos.platform=metal
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - talos.config=http://$PUBLIC_IP:9091/configdata?uuid=
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">  initrd:
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">    url: &#34;https://github.com/talos-systems/talos/releases/latest/download/initramfs-amd64.xz&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">    sha512: &#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">EOF</span>
</span></span></code></pre></div><h2 id="create-server-class">Create Server Class</h2>
<p>We must now create a server class to wrap our servers we registered.
This is necessary for using the Talos control plane provider for Cluster API.
The qualifiers needed for your server class will differ based on the data provided by your registration flow.
See the <a href="/docs/v0.1/configuration/serverclasses">server class docs</a> for more info on how these work.</p>
<p>Here is an example of how to apply the server class once you have the proper info:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#2aa198">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">apiVersion: metal.sidero.dev/v1alpha1
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">kind: ServerClass
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">  name: default
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">  qualifiers:
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">    cpu:
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">      - manufacturer: Intel(R) Corporation
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">        version: Intel(R) Atom(TM) CPU C3558 @ 2.20GHz
</span></span></span><span style="display:flex;"><span><span style="color:#2aa198">EOF</span>
</span></span></code></pre></div><p>In order to fetch hardware information, you can use</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get server -o yaml
</span></span></code></pre></div><p>Note that for bare-metal setup, you would need to specify an installation disk.
See the <a href="/docs/v0.1/configuration/servers/#installation-disk">Installation Disk</a></p>
<p>Once created, you should see the servers that make up your server class appear as &ldquo;available&rdquo;:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get serverclass
</span></span><span style="display:flex;"><span>NAME      AVAILABLE                                  IN USE
</span></span><span style="display:flex;"><span>default   <span style="color:#719e07">[</span><span style="color:#2aa198">&#34;00000000-0000-0000-0000-d05099d33360&#34;</span><span style="color:#719e07">]</span>   <span style="color:#719e07">[]</span>
</span></span></code></pre></div><h2 id="create-management-plane">Create Management Plane</h2>
<p>We are now ready to template out our management plane.
Using clusterctl, we can create a cluster manifest with:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>clusterctl config cluster management-plane -i sidero &gt; management-plane.yaml
</span></span></code></pre></div><p>Note that there are several variables that should be set in order for the templating to work properly:</p>
<ul>
<li><code>CONTROL_PLANE_ENDPOINT</code>: The endpoint used for the Kubernetes API server (e.g. <code>https://1.2.3.4:6443</code>).
This is the equivalent of the <code>endpoint</code> you would specify in <code>talosctl gen config</code>.
There are a variety of ways to configure a control plane endpoint.
Some common ways for an HA setup are to use DNS, a load balancer, or BGP.
A simpler method is to use the IP of a single node.
This has the disadvantage of being a single point of failure, but it can be a simple way to get running.</li>
<li><code>CONTROL_PLANE_SERVERCLASS</code>: The server class to use for control plane nodes.</li>
<li><code>WORKER_SERVERCLASS</code>: The server class to use for worker nodes.</li>
<li><code>KUBERNETES_VERSION</code>: The version of Kubernetes to deploy (e.g. <code>v1.19.4</code>).</li>
<li><code>CONTROL_PLANE_PORT</code>: The port used for the Kubernetes API server (port 6443)</li>
</ul>
<p>For instance:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#b58900">export</span> <span style="color:#268bd2">CONTROL_PLANE_SERVERCLASS</span><span style="color:#719e07">=</span>master
</span></span><span style="display:flex;"><span><span style="color:#b58900">export</span> <span style="color:#268bd2">WORKER_SERVERCLASS</span><span style="color:#719e07">=</span>worker
</span></span><span style="display:flex;"><span><span style="color:#b58900">export</span> <span style="color:#268bd2">KUBERNETES_VERSION</span><span style="color:#719e07">=</span>v1.20.1
</span></span><span style="display:flex;"><span><span style="color:#b58900">export</span> <span style="color:#268bd2">CONTROL_PLANE_PORT</span><span style="color:#719e07">=</span><span style="color:#2aa198">6443</span>
</span></span><span style="display:flex;"><span><span style="color:#b58900">export</span> <span style="color:#268bd2">CONTROL_PLANE_ENDPOINT</span><span style="color:#719e07">=</span>1.2.3.4
</span></span><span style="display:flex;"><span>clusterctl config cluster management-plane -i sidero &gt; management-plane.yaml
</span></span></code></pre></div><p>In addition, you can specify the replicas for control-plane &amp; worker nodes in management-plane.yaml manifest for TalosControlPlane and MachineDeployment objects.
Also, they can be scaled if needed:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get taloscontrolplane
</span></span><span style="display:flex;"><span>kubectl get machinedeployment
</span></span><span style="display:flex;"><span>kubectl scale taloscontrolplane management-plane-cp --replicas<span style="color:#719e07">=</span><span style="color:#2aa198">3</span>
</span></span></code></pre></div><p>Now that we have the manifest, we can simply apply it:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f management-plane.yaml
</span></span></code></pre></div><p><strong>NOTE: The templated manifest above is meant to act as a starting point.</strong>
<strong>If customizations are needed to ensure proper setup of your Talos cluster, they should be added before applying.</strong></p>
<p>Once the management plane is setup, you can fetch the talosconfig by using the cluster label.
Be sure to update the cluster name and issue the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get talosconfig <span style="color:#cb4b16">\
</span></span></span><span style="display:flex;"><span><span style="color:#cb4b16"></span>  -l cluster.x-k8s.io/cluster-name<span style="color:#719e07">=</span>&lt;CLUSTER NAME&gt; <span style="color:#cb4b16">\
</span></span></span><span style="display:flex;"><span><span style="color:#cb4b16"></span>  -o yaml -o <span style="color:#268bd2">jsonpath</span><span style="color:#719e07">=</span><span style="color:#2aa198">&#39;{.items[0].status.talosConfig}&#39;</span> &gt; management-plane-talosconfig.yaml
</span></span></code></pre></div><p>With the talosconfig in hand, the management plane&rsquo;s kubeconfig can be fetched with <code>talosctl --talosconfig management-plane-talosconfig.yaml kubeconfig</code></p>
<h2 id="pivoting">Pivoting</h2>
<p>Once we have the kubeconfig for the management cluster, we now have the ability to pivot the cluster from our bootstrap.
Using clusterctl, issue:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>clusterctl init --kubeconfig<span style="color:#719e07">=</span>/path/to/management-plane/kubeconfig -i sidero -b talos -c talos
</span></span></code></pre></div><p>Followed by:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>clusterctl move --to-kubeconfig<span style="color:#719e07">=</span>/path/to/management-plane/kubeconfig
</span></span></code></pre></div><p>Upon completion of this command, we can now tear down our bootstrap cluster with <code>talosctl cluster destroy</code> and begin using our management plane as our point of creation for all future clusters!</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-4d9f3827e7755ecc806058696c1d2359">2 - Creating Your First Cluster</h1>
    <div class="lead">A guide for creating your first cluster with the Sidero management plane</div>
	<h2 id="introduction">Introduction</h2>
<p>This guide will detail the steps needed to provision your first bare metal Talos cluster after completing the bootstrap and pivot steps detailed in the previous guide.
There will be two main steps in this guide: reconfiguring the Sidero components now that they have been pivoted and the actual cluster creation.</p>
<h2 id="reconfigure-sidero">Reconfigure Sidero</h2>
<h3 id="patch-services">Patch Services</h3>
<p>In this guide, we will convert the metadata service to a NodePort service and the other services to use host networking.
This is also necessary because some protocols like TFTP don&rsquo;t allow for port configuration.
Along with some nodeSelectors and a scale up of the metal controller manager deployment, creating the services this way allows for the creation of DNS names that point to all management plane nodes and provide an HA experience if desired.
It should also be noted, however, that there are many options for acheiving this functionality.
Users can look into projects like MetalLB or KubeRouter with BGP and ECMP if they desire something else.</p>
<p>Metal Controller Manager:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#586e75">## Use host networking</span>
</span></span><span style="display:flex;"><span>kubectl patch deploy -n sidero-system sidero-controller-manager --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/spec/template/spec/hostNetwork&#34;, &#34;value&#34;: true}]&#39;</span>
</span></span></code></pre></div><p>Metadata Server:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#586e75">## Convert metadata server service to nodeport</span>
</span></span><span style="display:flex;"><span>kubectl patch service -n sidero-system sidero-metadata-server --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/type&#34;, &#34;value&#34;: &#34;NodePort&#34;}]&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#586e75">## Set a known nodeport for metadata server</span>
</span></span><span style="display:flex;"><span>kubectl patch service -n sidero-system sidero-metadata-server --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/ports&#34;, &#34;value&#34;: [{&#34;port&#34;: 80, &#34;protocol&#34;: &#34;TCP&#34;, &#34;targetPort&#34;: &#34;http&#34;, &#34;nodePort&#34;: 30005}]}]&#39;</span>
</span></span></code></pre></div><h4 id="update-environment">Update Environment</h4>
<p>The metadata server&rsquo;s information needs to be updated in the default environment.
Edit the environment with <code>kubectl edit environment default</code> and update the <code>talos.config</code> kernel arg with the IP of one of the management plane nodes (or the DNS entry you created) and the nodeport we specified above (30005).</p>
<h3 id="update-dhcp">Update DHCP</h3>
<p>The DHCP options configured in the previous guide should now be updated to point to your new management plane IP or to the DNS name if it was created.</p>
<p>A revised ipxe-metal.conf file looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>allow bootp;
</span></span><span style="display:flex;"><span>allow booting;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>next-server 192.168.254.2;
</span></span><span style="display:flex;"><span><span style="color:#719e07">if</span> exists user-class and option user-class <span style="color:#719e07">=</span> <span style="color:#2aa198">&#34;iPXE&#34;</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>  filename <span style="color:#2aa198">&#34;http://192.168.254.2:8081/boot.ipxe&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#719e07">}</span> <span style="color:#719e07">else</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#719e07">if</span> substring <span style="color:#719e07">(</span>option vendor-class-identifier, 15, 5<span style="color:#719e07">)</span> <span style="color:#719e07">=</span> <span style="color:#2aa198">&#34;00000&#34;</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#586e75"># BIOS</span>
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">if</span> substring <span style="color:#719e07">(</span>option vendor-class-identifier, 0, 10<span style="color:#719e07">)</span> <span style="color:#719e07">=</span> <span style="color:#2aa198">&#34;HTTPClient&#34;</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>      option vendor-class-identifier <span style="color:#2aa198">&#34;HTTPClient&#34;</span>;
</span></span><span style="display:flex;"><span>      filename <span style="color:#2aa198">&#34;http://192.168.254.2:8081/tftp/undionly.kpxe&#34;</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">}</span> <span style="color:#719e07">else</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>      filename <span style="color:#2aa198">&#34;undionly.kpxe&#34;</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#719e07">}</span> <span style="color:#719e07">else</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#586e75"># UEFI</span>
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">if</span> substring <span style="color:#719e07">(</span>option vendor-class-identifier, 0, 10<span style="color:#719e07">)</span> <span style="color:#719e07">=</span> <span style="color:#2aa198">&#34;HTTPClient&#34;</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>      option vendor-class-identifier <span style="color:#2aa198">&#34;HTTPClient&#34;</span>;
</span></span><span style="display:flex;"><span>      filename <span style="color:#2aa198">&#34;http://192.168.254.2:8081/tftp/ipxe.efi&#34;</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">}</span> <span style="color:#719e07">else</span> <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>      filename <span style="color:#2aa198">&#34;ipxe.efi&#34;</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#719e07">}</span>
</span></span><span style="display:flex;"><span><span style="color:#719e07">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>host talos-mgmt-0 <span style="color:#719e07">{</span>
</span></span><span style="display:flex;"><span>   fixed-address 192.168.254.2;
</span></span><span style="display:flex;"><span>   hardware ethernet d0:50:99:d3:33:60;
</span></span><span style="display:flex;"><span><span style="color:#719e07">}</span>
</span></span></code></pre></div><h2 id="register-the-servers">Register the Servers</h2>
<p>At this point, any servers on the same network as Sidero should PXE boot using the Sidero PXE service.
To register a server with Sidero, simply turn it on and Sidero will do the rest.
Once the registration is complete, you should see the servers registered with <code>kubectl get servers</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get servers -o wide
</span></span><span style="display:flex;"><span>NAME                                   HOSTNAME        ACCEPTED   ALLOCATED   CLEAN
</span></span><span style="display:flex;"><span>00000000-0000-0000-0000-d05099d33360   192.168.254.2   <span style="color:#b58900">false</span>      <span style="color:#b58900">false</span>       <span style="color:#b58900">false</span>
</span></span></code></pre></div><h2 id="accept-the-servers">Accept the Servers</h2>
<p>Note in the output above that the newly registered servers are not <code>accepted</code>.
In order for a server to be eligible for consideration, it <em>must</em> be marked as <code>accepted</code>.
Before a <code>Server</code> is accepted, no write action will be performed against it.
Servers can be accepted by issuing a patch command like:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl patch server 00000000-0000-0000-0000-d05099d33360 --type<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;json&#39;</span> -p<span style="color:#719e07">=</span><span style="color:#2aa198">&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/accepted&#34;, &#34;value&#34;: true}]&#39;</span>
</span></span></code></pre></div><p>For more information on server acceptance, see the <a href="/docs/v0.1/configuration/servers">server docs</a>.</p>
<h2 id="create-the-cluster">Create the Cluster</h2>
<p>The cluster creation process should be identical to what was detailed in the previous guide.
Note that, for this example, the same &ldquo;default&rdquo; serverclass that we used in the previous guide is used again.
Using clusterctl, we can create a cluster manifest with:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>clusterctl config cluster workload-cluster -i sidero &gt; workload-cluster.yaml
</span></span></code></pre></div><p>Note that there are several variables that should be set in order for the templating to work properly:</p>
<ul>
<li><code>CONTROL_PLANE_ENDPOINT</code>: The endpoint used for the Kubernetes API server (e.g. <code>https://1.2.3.4:6443</code>).
This is the equivalent of the <code>endpoint</code> you would specify in <code>talosctl gen config</code>.
There are a variety of ways to configure a control plane endpoint.
Some common ways for an HA setup are to use DNS, a load balancer, or BGP.
A simpler method is to use the IP of a single node.
This has the disadvantage of being a single point of failure, but it can be a simple way to get running.</li>
<li><code>CONTROL_PLANE_SERVERCLASS</code>: The server class to use for control plane nodes.</li>
<li><code>WORKER_SERVERCLASS</code>: The server class to use for worker nodes.</li>
<li><code>KUBERNETES_VERSION</code>: The version of Kubernetes to deploy (e.g. <code>v1.19.4</code>).</li>
</ul>
<p>Now that we have the manifest, we can simply apply it:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f workload-cluster.yaml
</span></span></code></pre></div><p><strong>NOTE: The templated manifest above is meant to act as a starting point.</strong>
<strong>If customizations are needed to ensure proper setup of your Talos cluster, they should be added before applying.</strong></p>
<p>Once the workload cluster is setup, you can fetch the talosconfig with a command like:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get talosconfig -o yaml workload-cluster-cp-xxx -o <span style="color:#268bd2">jsonpath</span><span style="color:#719e07">=</span><span style="color:#2aa198">&#39;{.status.talosConfig}&#39;</span> &gt; workload-cluster-talosconfig.yaml
</span></span></code></pre></div><p>Then the workload cluster&rsquo;s kubeconfig can be fetched with <code>talosctl --talosconfig workload-cluster-talosconfig.yaml kubeconfig /desired/path</code>.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-6a83ec7ccd4d033a9248a54355ce6a91">3 - Patching</h1>
    <div class="lead">A guide describing patching</div>
	<p>Server resources can be updated by using the <code>configPatches</code> section of the custom resource.
Any field of the <a href="https://www.talos.dev/latest/reference/configuration/">Talos machine config</a>
can be overridden on a per-machine basis using this method.
The format of these patches is based on <a href="http://jsonpatch.com/">JSON 6902</a> that you may be used to in tools like kustomize.</p>
<p>Any patches specified in the server resource are processed by the Metal Metadata Server before it returns a Talos machine config for a given server at boot time.</p>
<p>A set of patches may look like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#268bd2">apiVersion</span>: metal.sidero.dev/v1alpha1
</span></span><span style="display:flex;"><span><span style="color:#268bd2">kind</span>: Server
</span></span><span style="display:flex;"><span><span style="color:#268bd2">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#268bd2">name</span>: <span style="color:#2aa198">00000000-0000-0000-0000</span>-d05099d33360
</span></span><span style="display:flex;"><span><span style="color:#268bd2">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#268bd2">configPatches</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#268bd2">op</span>: replace
</span></span><span style="display:flex;"><span>      <span style="color:#268bd2">path</span>: /machine/install
</span></span><span style="display:flex;"><span>      <span style="color:#268bd2">value</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">disk</span>: /dev/sda
</span></span><span style="display:flex;"><span>    - <span style="color:#268bd2">op</span>: replace
</span></span><span style="display:flex;"><span>      <span style="color:#268bd2">path</span>: /cluster/network/cni
</span></span><span style="display:flex;"><span>      <span style="color:#268bd2">value</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">name</span>: <span style="color:#2aa198">&#34;custom&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">urls</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#2aa198">&#34;http://192.168.1.199/assets/cilium.yaml&#34;</span>
</span></span></code></pre></div><h2 id="testing-configuration-patches">Testing Configuration Patches</h2>
<p>While developing config patches it is usually convenient to test generated config with patches
before actual server is provisioned with the config.</p>
<p>This can be achieved by querying the metadata server endpoint directly:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>$ curl http://<span style="color:#268bd2">$PUBLIC_IP</span>:9091/configdata?uuid<span style="color:#719e07">=</span><span style="color:#268bd2">$SERVER_UUID</span>
</span></span><span style="display:flex;"><span>version: v1alpha1
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>Replace <code>$PUBLIC_IP</code> with the Sidero IP address and <code>$SERVER_UUID</code> with the name of the <code>Server</code> to test
against.</p>
<p>If metadata endpoint returns an error on applying JSON patches, make sure config subtree being patched exists in the config.
If it doesn&rsquo;t exist, create it with the <code>op: add</code> above the <code>op: replace</code> patch.</p>
<h2 id="combining-patches-from-multiple-sources">Combining Patches from Multiple Sources</h2>
<p>Config patches might be combined from multiple sources (<code>Server</code>, <code>ServerClass</code>), which is explained in details
in <a href="../../configuration/metadata/">Metadata</a> section.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-c0b04d8cb5ac9d8994644df9aea859db">4 - Provisioning Flow</h1>
    <div class="lead">Diagrams for various flows in Sidero.</div>
	<pre tabindex="0"><code class="language-mermaid" data-lang="mermaid">graph TD;
    Start(Start);
    End(End);

    %% Decisions

    IsOn{Is server is powered on?};
    IsRegistered{Is server is registered?};
    IsAccepted{Is server is accepted?};
    IsClean{Is server is clean?};
    IsAllocated{Is server is allocated?};

    %% Actions

    DoPowerOn[Power server on];
    DoPowerOff[Power server off];
    DoBootAgentEnvironment[Boot agent];
    DoBootEnvironment[Boot environment];
    DoRegister[Register server];
    DoWipe[Wipe server];

    %% Chart

    Start--&gt;IsOn;
    IsOn--Yes--&gt;End;
    IsOn--No--&gt;DoPowerOn;

    DoPowerOn---&gt;IsRegistered;

    IsRegistered--Yes---&gt;IsAccepted;
    IsRegistered--No---&gt;DoBootAgentEnvironment--&gt;DoRegister;

    DoRegister--&gt;IsRegistered;

    IsAccepted--Yes---&gt;IsAllocated;
    IsAccepted--No---&gt;End;

    IsAllocated--Yes---&gt;DoBootEnvironment;
    IsAllocated--No---&gt;IsClean;
    IsClean--No---&gt;DoWipe--&gt;DoPowerOff;

    IsClean--Yes---&gt;DoPowerOff;

    DoBootEnvironment--&gt;End;

    DoPowerOff--&gt;End;
</code></pre><h2 id="installation-flow">Installation Flow</h2>
<pre tabindex="0"><code class="language-mermaid" data-lang="mermaid">graph TD;
    Start(Start);
    End(End);

    %% Decisions

    IsInstalled{Is installed};

    %% Actions

    DoInstall[Install];
    DoReboot[Reboot];

    %% Chart

    Start--&gt;IsInstalled;
    IsInstalled--Yes--&gt;End;
    IsInstalled--No--&gt;DoInstall;

    DoInstall--&gt;DoReboot;

    DoReboot--&gt;IsInstalled;
</code></pre>
</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" rel="noopener" href="https://twitter.com/SideroLabs" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/siderolabs" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-4 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2022 Sidero Labs, Inc. All Rights Reserved</small>
        
	
		
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"
    integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js"
    integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA=="
    crossorigin="anonymous"></script>





<script src='/js/tabpane-persist.js'></script>


















<script src="/js/main.min.68e31ec429bf4c76d0cfc803a06912682cfe4274c4cafeb4d70d00cfe3c3b618.js" integrity="sha256-aOMexCm/THbQz8gDoGkSaCz&#43;QnTEyv601w0Az&#43;PDthg=" crossorigin="anonymous"></script>








<script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>



<script>
  docsearch({
    appId: "0UBMNL8U2A",
    apiKey: "b23cc1d9c0b406b2d1b83f0c652ead8a",
    indexName: "sidero",
    container: '#algolia-search',
    debug: true,
    searchParameters: {
      facetFilters: ['version:v0.1'],
    },
  });
</script>






<meta name="docsearch:version" content="v0.1" />




  </body>
</html>
